{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article  \n",
    "import csv \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling News "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"https://timesofindia.indiatimes.com\"\n",
    "r = requests.get(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content, 'html5lib') \n",
    "table = soup.findAll('a', attrs = {'class':'w_img'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indianews=[]\n",
    "for row in table: \n",
    "    if not row['href'].startswith('http'):\n",
    "        indianews.append('https://timesofindia.indiatimes.com'+row['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=[]\n",
    "for i in indianews:\n",
    "    article = Article(i, language=\"en\")\n",
    "    article.download() \n",
    "    article.parse() \n",
    "    article.nlp() \n",
    "    data={}\n",
    "    data['Title']=article.title\n",
    "    data['Text']=article.text\n",
    "    data['Summary']=article.summary\n",
    "    data['Keywords']=article.keywords\n",
    "    dataframe.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[patients, single, toll, number, reports, day,...</td>\n",
       "      <td>Paramedics wearing protective suits amid fears...</td>\n",
       "      <td>Paramedics wearing protective suits amid fears...</td>\n",
       "      <td>Maharashtra reports 27 Covid-19 deaths, highes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[marson, trust, results, tests, team, positive...</td>\n",
       "      <td>At the least, the finding could greatly compli...</td>\n",
       "      <td>The researchers worked around the clock, in sh...</td>\n",
       "      <td>Coronavirus antibody tests: Can you trust the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[trials, global, gets, trial, patients, clinic...</td>\n",
       "      <td>“It won’t be a success until the drug gets app...</td>\n",
       "      <td>A Chinese drugmaker has received approval from...</td>\n",
       "      <td>Chinese alzheimer’s drug gets U.S. approval fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[fever, university, cabinet, pharmacy, doctor,...</td>\n",
       "      <td>Here is the medicine and equipment they recomm...</td>\n",
       "      <td>Right now, there is no cure for the coronaviru...</td>\n",
       "      <td>How should you stock your medicine cabinet?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[crisis, patients, heart, attack, nissen, stro...</td>\n",
       "      <td>“Everywhere, the coronavirus .”After a few day...</td>\n",
       "      <td>Bishnu Virachan was a bicycle deliveryman for ...</td>\n",
       "      <td>Amid the coronavirus crisis, heart and stroke ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Keywords  \\\n",
       "0  [patients, single, toll, number, reports, day,...   \n",
       "1  [marson, trust, results, tests, team, positive...   \n",
       "2  [trials, global, gets, trial, patients, clinic...   \n",
       "3  [fever, university, cabinet, pharmacy, doctor,...   \n",
       "4  [crisis, patients, heart, attack, nissen, stro...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Paramedics wearing protective suits amid fears...   \n",
       "1  At the least, the finding could greatly compli...   \n",
       "2  “It won’t be a success until the drug gets app...   \n",
       "3  Here is the medicine and equipment they recomm...   \n",
       "4  “Everywhere, the coronavirus .”After a few day...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Paramedics wearing protective suits amid fears...   \n",
       "1  The researchers worked around the clock, in sh...   \n",
       "2  A Chinese drugmaker has received approval from...   \n",
       "3  Right now, there is no cure for the coronaviru...   \n",
       "4  Bishnu Virachan was a bicycle deliveryman for ...   \n",
       "\n",
       "                                               Title  \n",
       "0  Maharashtra reports 27 Covid-19 deaths, highes...  \n",
       "1  Coronavirus antibody tests: Can you trust the ...  \n",
       "2  Chinese alzheimer’s drug gets U.S. approval fo...  \n",
       "3        How should you stock your medicine cabinet?  \n",
       "4  Amid the coronavirus crisis, heart and stroke ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(dataframe)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for predicting virality of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset=\"OnlineNewsPopularity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cols(data):\n",
    "    \"\"\"Clean the column names by stripping and lowercase.\"\"\"\n",
    "    clean_col_map = {x: x.lower().strip() for x in list(data)}\n",
    "    return data.rename(index=str, columns=clean_col_map)\n",
    "\n",
    "def TrainTestSplit(X, Y, R=0, test_size=0.2):\n",
    "    \"\"\"Easy Train Test Split call.\"\"\"\n",
    "    return train_test_split(X, Y, test_size=test_size, random_state=R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "dataset = clean_cols(pd.read_csv(Dataset))\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.20, random_state=42)\n",
    "\n",
    "x_train = train_set.drop(['url','shares', 'timedelta', 'lda_00','lda_01','lda_02','lda_03','lda_04','num_self_hrefs', 'kw_min_min', 'kw_max_min', 'kw_avg_min','kw_min_max','kw_max_max','kw_avg_max','kw_min_avg','kw_max_avg','kw_avg_avg','self_reference_min_shares','self_reference_max_shares','self_reference_avg_sharess','rate_positive_words','rate_negative_words','abs_title_subjectivity','abs_title_sentiment_polarity'], axis=1)\n",
    "y_train = train_set['shares']\n",
    "\n",
    "x_test = test_set.drop(['url','shares', 'timedelta', 'num_self_hrefs', 'kw_min_min', 'kw_max_min', 'kw_avg_min','kw_min_max','kw_max_max','kw_avg_max','kw_min_avg','kw_max_avg','kw_avg_avg','self_reference_min_shares','self_reference_max_shares','self_reference_avg_sharess','rate_positive_words','rate_negative_words','abs_title_subjectivity','abs_title_sentiment_polarity'], axis=1)\n",
    "y_test = test_set['shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVR(kernel='rbf')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_res = pd.DataFrame(clf.predict(x_train),list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual shares</th>\n",
       "      <th>Predicted shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16100</td>\n",
       "      <td>1407.673163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>508</td>\n",
       "      <td>1402.412021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300</td>\n",
       "      <td>1398.077211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3100</td>\n",
       "      <td>1399.904678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6900</td>\n",
       "      <td>1412.927887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual shares  Predicted shares\n",
       "0          16100       1407.673163\n",
       "1            508       1402.412021\n",
       "2           1300       1398.077211\n",
       "3           3100       1399.904678\n",
       "4           6900       1412.927887"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_res.reset_index(level=0, inplace=True)\n",
    "rf_res_df = rf_res.rename(index=str, columns={\"index\": \"Actual shares\", 0: \"Predicted shares\"})\n",
    "rf_res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Crawled News according to Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ragnarock/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_unique(words):\n",
    "    words=tokenize(words)\n",
    "    no_order = list(set(words))\n",
    "    rate_unique=len(no_order)/len(words)\n",
    "    return rate_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_nonstop(words):\n",
    "    words=tokenize(words)\n",
    "    filtered_sentence = [w for w in words if not w in stopwords]\n",
    "    rate_nonstop=len(filtered_sentence)/len(words)\n",
    "    no_order = list(set(filtered_sentence))\n",
    "    rate_unique_nonstop=len(no_order)/len(words)\n",
    "    return rate_nonstop,rate_unique_nonstop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_token(words):\n",
    "    words=tokenize(words)\n",
    "    length=[]\n",
    "    for i in words:\n",
    "        length.append(len(i))\n",
    "    return np.average(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datefinder\n",
    "import datetime  \n",
    "from datetime import date \n",
    "def day(article_text):\n",
    "    article=article_text\n",
    "    if len(list(datefinder.find_dates(article)))>0:\n",
    "        date=str(list(datefinder.find_dates(article))[0])\n",
    "        date=date.split()\n",
    "        date=date[0]\n",
    "        year, month, day = date.split('-')     \n",
    "        day_name = datetime.date(int(year), int(month), int(day)) \n",
    "        return day_name.strftime(\"%A\")\n",
    "    return \"Monday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text=text\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words=[]\n",
    "neg_words=[]\n",
    "def polar(words):\n",
    "    all_tokens=tokenize(words)\n",
    "    for i in all_tokens:\n",
    "        analysis=TextBlob(i)\n",
    "        polarity=analysis.sentiment.polarity\n",
    "        if polarity>0:\n",
    "            pos_words.append(i)\n",
    "        if polarity<0:\n",
    "            neg_words.append(i)\n",
    "    return pos_words,neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rates(words):\n",
    "    words=polar(words)\n",
    "    pos=words[0]\n",
    "    neg=words[1]\n",
    "    all_words=words\n",
    "    global_rate_positive_words=(len(pos)/len(all_words))/100\n",
    "    global_rate_negative_words=(len(neg)/len(all_words))/100\n",
    "    pol_pos=[]\n",
    "    pol_neg=[]\n",
    "    for i in pos:\n",
    "        analysis=TextBlob(i)\n",
    "        pol_pos.append(analysis.sentiment.polarity)\n",
    "        avg_positive_polarity=analysis.sentiment.polarity\n",
    "    for j in neg:\n",
    "        analysis2=TextBlob(j)\n",
    "        pol_neg.append(analysis2.sentiment.polarity)\n",
    "        avg_negative_polarity=analysis2.sentiment.polarity\n",
    "    min_positive_polarity=min(pol_pos)\n",
    "    max_positive_polarity=max(pol_pos)\n",
    "    min_negative_polarity=min(pol_neg)\n",
    "    max_negative_polarity=max(pol_neg)\n",
    "    avg_positive_polarity=np.average(pol_pos)\n",
    "    avg_negative_polarity=np.average(pol_neg)\n",
    "    return global_rate_positive_words,global_rate_negative_words,avg_positive_polarity,min_positive_polarity,max_positive_polarity,avg_negative_polarity,min_negative_polarity,max_negative_polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes=[]\n",
    "for i in indianews:\n",
    "    pred_info={}\n",
    "    article = Article(i, language=\"en\") \n",
    "    article.download() \n",
    "    article.parse()\n",
    "    analysis=TextBlob(article.text)\n",
    "    polarity=analysis.sentiment.polarity\n",
    "    title_analysis=TextBlob(article.title)\n",
    "    pred_info['text']=article.text\n",
    "    pred_info['n_tokens_title']=len(tokenize(article.title))\n",
    "    pred_info['n_tokens_content']=len(tokenize(article.text))\n",
    "    pred_info['n_unique_tokens']=rate_unique(article.text)\n",
    "    pred_info['n_non_stop_words']=rate_nonstop(article.text)[0]\n",
    "    pred_info['n_non_stop_unique_tokens']=rate_nonstop(article.text)[1]\n",
    "    pred_info['num_hrefs']=article.html.count(\"https://timesofindia.indiatimes.com\")\n",
    "    pred_info['num_imgs']=len(article.images)\n",
    "    pred_info['num_videos']=len(article.movies)\n",
    "    pred_info['average_token_length']=avg_token(article.text)\n",
    "    pred_info['num_keywords']=len(article.keywords)\n",
    "    \n",
    "    if \"life-style\" in article.url:\n",
    "        pred_info['data_channel_is_lifestyle']=1\n",
    "    else:\n",
    "        pred_info['data_channel_is_lifestyle']=0\n",
    "    if \"etimes\" in article.url:\n",
    "        pred_info['data_channel_is_entertainment']=1\n",
    "    else:\n",
    "        pred_info['data_channel_is_entertainment']=0\n",
    "    if \"business\" in article.url:\n",
    "        pred_info['data_channel_is_bus']=1\n",
    "    else:\n",
    "        pred_info['data_channel_is_bus']=0\n",
    "    if \"social media\" or \"facebook\" or \"whatsapp\" in article.text.lower():\n",
    "        data_channel_is_socmed=1\n",
    "        data_channel_is_tech=0\n",
    "        data_channel_is_world=0\n",
    "    else:\n",
    "        data_channel_is_socmed=0\n",
    "    if (\"technology\" or \"tech\" in article.text.lower()) or (\"technology\" or \"tech\" in article.url):\n",
    "        data_channel_is_tech=1\n",
    "        data_channel_is_socmed=0\n",
    "        data_channel_is_world=0\n",
    "    else:\n",
    "        data_channel_is_tech=0\n",
    "    if \"world\" in article.url:\n",
    "        data_channel_is_world=1\n",
    "        data_channel_is_tech=0\n",
    "        data_channel_is_socmed=0\n",
    "    else:\n",
    "        data_channel_is_world=0\n",
    "        \n",
    "    pred_info['data_channel_is_socmed']=data_channel_is_socmed\n",
    "    pred_info['data_channel_is_tech']=data_channel_is_tech\n",
    "    pred_info['data_channel_is_world']=data_channel_is_world\n",
    "    \n",
    "    if day(i)==\"Monday\":\n",
    "        pred_info['weekday_is_monday']=1\n",
    "    else:\n",
    "        pred_info['weekday_is_monday']=0\n",
    "    if day(i)==\"Tuesday\":\n",
    "        pred_info['weekday_is_tuesday']=1\n",
    "    else:\n",
    "        pred_info['weekday_is_tuesday']=0\n",
    "    if day(i)==\"Wednesday\":\n",
    "        pred_info['weekday_is_wednesday']=1\n",
    "    else:\n",
    "        pred_info['weekday_is_wednesday']=0\n",
    "    if day(i)==\"Thursday\":\n",
    "        pred_info['weekday_is_thursday']=1\n",
    "    else:\n",
    "        pred_info['weekday_is_thursday']=0\n",
    "    if day(i)==\"Friday\":\n",
    "        pred_info['weekday_is_friday']=1\n",
    "    else:\n",
    "        pred_info['weekday_is_friday']=0\n",
    "    if day(i)==\"Saturday\":\n",
    "        pred_info['weekday_is_saturday']=1\n",
    "        pred_info['is_weekend']=1\n",
    "    else:\n",
    "        pred_info['weekday_is_saturday']=0\n",
    "    if day(i)==\"Sunday\":\n",
    "        pred_info['weekday_is_sunday']=1\n",
    "        pred_info['is_weekend']=1\n",
    "    else:\n",
    "        pred_info['weekday_is_sunday']=0\n",
    "        pred_info['is_weekend']=0\n",
    "        \n",
    "    pred_info['global_subjectivity']=analysis.sentiment.subjectivity\n",
    "    pred_info['global_sentiment_polarity']=analysis.sentiment.polarity\n",
    "    pred_info['global_rate_positive_words']=rates(article.text)[0]\n",
    "    pred_info['global_rate_negative_words']=rates(article.text)[1]\n",
    "    pred_info['avg_positive_polarity']=rates(article.text)[2]\n",
    "    pred_info['min_positive_polarity']=rates(article.text)[3]\n",
    "    pred_info['max_positive_polarity']=rates(article.text)[4]\n",
    "    pred_info['avg_negative_polarity']=rates(article.text)[5]\n",
    "    pred_info['min_negative_polarity']=rates(article.text)[6]\n",
    "    pred_info['max_negative_polarity']=rates(article.text)[7]    \n",
    "    pred_info['title_subjectivity']=title_analysis.sentiment.subjectivity\n",
    "    pred_info['title_sentiment_polarity']=title_analysis.sentiment.polarity\n",
    "    dataframes.append(pred_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>...</th>\n",
       "      <th>text</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.664463</td>\n",
       "      <td>-0.202315</td>\n",
       "      <td>0.257771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>Paramedics wearing protective suits amid fears...</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.535697</td>\n",
       "      <td>-0.272855</td>\n",
       "      <td>0.285822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>The researchers worked around the clock, in sh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.613221</td>\n",
       "      <td>-0.274257</td>\n",
       "      <td>0.297307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>A Chinese drugmaker has received approval from...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.399364</td>\n",
       "      <td>-0.302664</td>\n",
       "      <td>0.320087</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>...</td>\n",
       "      <td>Right now, there is no cure for the coronaviru...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.217837</td>\n",
       "      <td>-0.304615</td>\n",
       "      <td>0.344639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>...</td>\n",
       "      <td>Bishnu Virachan was a bicycle deliveryman for ...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.072742</td>\n",
       "      <td>-0.302246</td>\n",
       "      <td>0.340834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>...</td>\n",
       "      <td>That frightening idea was raised by Dr. Robert...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.392086</td>\n",
       "      <td>-0.300911</td>\n",
       "      <td>0.345423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.17</td>\n",
       "      <td>...</td>\n",
       "      <td>Salman Rushdie is the flavor of the month once...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.304945</td>\n",
       "      <td>-0.296999</td>\n",
       "      <td>0.351329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.27</td>\n",
       "      <td>...</td>\n",
       "      <td>If there could be one magic ingredient that co...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.181287</td>\n",
       "      <td>-0.291360</td>\n",
       "      <td>0.357640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>...</td>\n",
       "      <td>Let’s face it, as a country, nothing unites us...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.149606</td>\n",
       "      <td>-0.291247</td>\n",
       "      <td>0.361824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.08</td>\n",
       "      <td>...</td>\n",
       "      <td>From supporting each other in their respective...</td>\n",
       "      <td>0.268182</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_token_length  avg_negative_polarity  avg_positive_polarity  \\\n",
       "0              4.664463              -0.202315               0.257771   \n",
       "1              4.535697              -0.272855               0.285822   \n",
       "2              4.613221              -0.274257               0.297307   \n",
       "3              4.399364              -0.302664               0.320087   \n",
       "4              4.217837              -0.304615               0.344639   \n",
       "5              4.072742              -0.302246               0.340834   \n",
       "6              4.392086              -0.300911               0.345423   \n",
       "7              4.304945              -0.296999               0.351329   \n",
       "8              4.181287              -0.291360               0.357640   \n",
       "9              4.149606              -0.291247               0.361824   \n",
       "\n",
       "   data_channel_is_bus  data_channel_is_entertainment  \\\n",
       "0                    0                              0   \n",
       "1                    0                              0   \n",
       "2                    0                              0   \n",
       "3                    0                              0   \n",
       "4                    0                              0   \n",
       "5                    0                              0   \n",
       "6                    0                              0   \n",
       "7                    0                              0   \n",
       "8                    0                              0   \n",
       "9                    0                              0   \n",
       "\n",
       "   data_channel_is_lifestyle  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "0                          0                       0                     1   \n",
       "1                          1                       0                     1   \n",
       "2                          1                       0                     1   \n",
       "3                          1                       0                     1   \n",
       "4                          1                       0                     1   \n",
       "5                          1                       0                     1   \n",
       "6                          1                       0                     1   \n",
       "7                          1                       0                     1   \n",
       "8                          1                       0                     1   \n",
       "9                          0                       0                     1   \n",
       "\n",
       "   data_channel_is_world  global_rate_negative_words          ...           \\\n",
       "0                      0                        0.06          ...            \n",
       "1                      0                        0.65          ...            \n",
       "2                      0                        1.97          ...            \n",
       "3                      0                        2.44          ...            \n",
       "4                      0                        3.34          ...            \n",
       "5                      0                        4.47          ...            \n",
       "6                      0                        5.17          ...            \n",
       "7                      0                        5.27          ...            \n",
       "8                      0                        5.62          ...            \n",
       "9                      0                        6.08          ...            \n",
       "\n",
       "                                                text  \\\n",
       "0  Paramedics wearing protective suits amid fears...   \n",
       "1  The researchers worked around the clock, in sh...   \n",
       "2  A Chinese drugmaker has received approval from...   \n",
       "3  Right now, there is no cure for the coronaviru...   \n",
       "4  Bishnu Virachan was a bicycle deliveryman for ...   \n",
       "5  That frightening idea was raised by Dr. Robert...   \n",
       "6  Salman Rushdie is the flavor of the month once...   \n",
       "7  If there could be one magic ingredient that co...   \n",
       "8  Let’s face it, as a country, nothing unites us...   \n",
       "9  From supporting each other in their respective...   \n",
       "\n",
       "   title_sentiment_polarity  title_subjectivity  weekday_is_friday  \\\n",
       "0                 -0.071429            0.214286                  0   \n",
       "1                  0.000000            0.000000                  0   \n",
       "2                  0.000000            0.000000                  0   \n",
       "3                  0.000000            0.000000                  0   \n",
       "4                 -0.200000            0.050000                  0   \n",
       "5                  0.000000            0.000000                  0   \n",
       "6                  0.000000            0.000000                  0   \n",
       "7                  0.500000            0.500000                  0   \n",
       "8                  0.600000            0.900000                  0   \n",
       "9                  0.268182            0.600000                  0   \n",
       "\n",
       "   weekday_is_monday  weekday_is_saturday  weekday_is_sunday  \\\n",
       "0                  1                    0                  0   \n",
       "1                  1                    0                  0   \n",
       "2                  1                    0                  0   \n",
       "3                  1                    0                  0   \n",
       "4                  1                    0                  0   \n",
       "5                  1                    0                  0   \n",
       "6                  1                    0                  0   \n",
       "7                  1                    0                  0   \n",
       "8                  0                    1                  0   \n",
       "9                  1                    0                  0   \n",
       "\n",
       "   weekday_is_thursday  weekday_is_tuesday  weekday_is_wednesday  \n",
       "0                    0                   0                     0  \n",
       "1                    0                   0                     0  \n",
       "2                    0                   0                     0  \n",
       "3                    0                   0                     0  \n",
       "4                    0                   0                     0  \n",
       "5                    0                   0                     0  \n",
       "6                    0                   0                     0  \n",
       "7                    0                   0                     0  \n",
       "8                    0                   0                     0  \n",
       "9                    0                   0                     0  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df=pd.DataFrame(dataframes)\n",
    "pred_test=pred_df.drop(['text'],axis=1)\n",
    "pred_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood of Virality of News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paramedics wearing protective suits amid fears...</td>\n",
       "      <td>1414.749769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The researchers worked around the clock, in sh...</td>\n",
       "      <td>1414.749769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Chinese drugmaker has received approval from...</td>\n",
       "      <td>1414.749769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right now, there is no cure for the coronaviru...</td>\n",
       "      <td>1414.749769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bishnu Virachan was a bicycle deliveryman for ...</td>\n",
       "      <td>1414.749769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     Virality\n",
       "0  Paramedics wearing protective suits amid fears...  1414.749769\n",
       "1  The researchers worked around the clock, in sh...  1414.749769\n",
       "2  A Chinese drugmaker has received approval from...  1414.749769\n",
       "3  Right now, there is no cure for the coronaviru...  1414.749769\n",
       "4  Bishnu Virachan was a bicycle deliveryman for ...  1414.749769"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2=pd.DataFrame(clf.predict(pred_test),pred_df['text'])\n",
    "test2.reset_index(level=0, inplace=True)\n",
    "test2 = test2.rename(index=str, columns={\"index\": \"News\", 0: \"Virality\"})\n",
    "test2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
